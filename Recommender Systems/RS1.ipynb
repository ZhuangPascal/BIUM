{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etudiants : <br/>\n",
    "3701123 - Pascal ZHUANG<br/>\n",
    "3416447 - Mohand BENCHABANE<br/>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommenders 1 -- (1h) \n",
    "\n",
    "## Goals of this practical:\n",
    "\n",
    "1. Have a quick statistical tour of a recommendation dataset (~10min)\n",
    "2. Understand the classical task of rating prediction (~10min)\n",
    "3. Know and implement really simple but tough baselines (~20min)\n",
    "4. Use a scikit like library to build explicit recommender sysems (~20min)\n",
    "\n",
    "\n",
    "## What is collaborative filtering ?\n",
    "\n",
    "On the internet, people rate items (or simply click on them, showing preference). All these ratings can be seen as a matrix coding for all ratings of size (n_user,n_item). It's worth noting that this matrix is highly sparse: No one rates everything, people only rate a subset of items. **Collaborative filtering** is done by leveraging the similarity in people's rating pattern. It enables to find \n",
    "\n",
    "\n",
    "Recommendation (more specifically **collaborative filtering**) goal can be seen as predicting how someone will rate one item. This is akin to filling this matrix, by predicting all missing ratings. The most used algorithms for this task are matrix factorization ones: they take advantage from the fact that a matrix can be decomposed into two sub-matrices: one coding for the users and one coding for the items.\n",
    "\n",
    "## Why predicting ratings and not directly items:\n",
    "\n",
    "Theoritically, the goal of a recommender system is to cherry pick interesting items for one user within a huge collection. Rating prediction is a surrogate problem of item prediction. To get what item to recommend you can, for exemple, simply sort best rated items. It has been shown that improving rating prediction actually improve item prediction.\n",
    "\n",
    "\n",
    "## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "In this practical we use a small dataset of user ratings on movies. Specifically, we treat the dataset as list of $(user,item,rating)$ triplets.\n",
    "\n",
    "\n",
    "\n",
    "## Notes: \n",
    "\n",
    "We'll be using pandas for data manipulation but it's not needed to know any special tricks. If you have any pandas related questions, just ask !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "First, we install and load some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this to install required packages if needed (and restart kernel !)\n",
    "#! pip install --upgrade pandas\n",
    "#! pip install --upgrade seaborn\n",
    "#! pip install --upgrade scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # we'll use pandas for data analysis\n",
    "import seaborn as sns # we'll use seaborn for nice plots\n",
    "import numpy as np # we'll use numpy for data also\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "0.11.1\n"
     ]
    }
   ],
   "source": [
    "#Should be 0.25.3\n",
    "print(pd.__version__)\n",
    "\n",
    "#Should be 0.9.0\n",
    "print(sns.__version__)\n",
    "\n",
    "## These are the version the notebook has been built on. It could work on old ones, or it could not :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Let's have a quick statistical tour of the ml-small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/) it is a subset of a bigger data set of movie ratings.\n",
    "\n",
    "> This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\n",
    "\n",
    "> Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's load the data with pandas and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"dataset/ratings.csv\")\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (WARMUP) Some simple questions we'll try to answer:\n",
    "- How many users are there ?\n",
    "- How many items are there ?\n",
    "- How are ratings distributed ? Per users ? Per items ?\n",
    "- What is the mean rating ?\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Find how many user and item there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 610 users and 9724 items\n"
     ]
    }
   ],
   "source": [
    "ratings[\"userId\"].values #numpy array\n",
    "ratings[\"movieId\"] #pandas serie\n",
    "#there are 610 users and 9724 items\n",
    "\n",
    "num_users  = len(np.unique(ratings[\"userId\"].values))\n",
    "num_items  = len(np.unique(ratings[\"movieId\"]))\n",
    "\n",
    "print(f\"there are {num_users} users and {num_items} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Find how sparse the rating matrix is.\n",
    "\n",
    "Rating data is often though of a user/item matrix. Since each user haven't rated every items this matrix is HIGHLY SPARSE (it's mainly filled with zeros). \n",
    "- Find the sparsity of the matrix (spoiler: it's ~1.69% full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating matrix is only 1.6999683055613624% full\n"
     ]
    }
   ],
   "source": [
    "#Rating matrix is only 1.6999683055613624% full\n",
    "\n",
    "sparsity = (ratings.shape[0]/(num_items * num_users))*100\n",
    "print(f\"Rating matrix is only {sparsity}% full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Lets compute some stats:\n",
    "\n",
    "- Find the count/mean/std/min/max of ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100836.000000\n",
       "mean          3.501557\n",
       "std           1.042529\n",
       "min           0.500000\n",
       "25%           3.000000\n",
       "50%           3.500000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.describe()['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find/plot the global rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1e71a934208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVvUlEQVR4nO3dfaze5X3f8fenJiQ4gMCNd8R4MLixqjlZR1IHWIm2PGhgaFfoljHQFrwI4kgxW1CzrtD9QZc0UqutacXkMBHwAC0NpQ0RNOUhHkWJMgWCeQiPQViEA3aJDTEBUqREnH73x30dcgeO7YN93+c6x+f9kn66f/f393T9juSPLl/37yFVhSRp7v1C7wZI0mJlAEtSJwawJHViAEtSJwawJHVyUO8GzLW1a9fWbbfd1rsZkhaXzFRcdD3g559/vncTJAlYhAEsSfOFASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnRjAktSJASxJnSy6p6FJGp2pqSkmJydf+75ixQqWLFnSsUULiwEsaZ9NTk5y4cZbWbpsgld27eCqDWewcuXK3s1aMAxgSftl6bIJDl1+dO9mLEiOAUtSJwawJHViAEtSJwawJHViAEtSJwawJHViAEtSJwawJHViAEtSJwawJHViAEtSJwawJHViAEtSJwawJHViAEtSJ2ML4CTHJrkzyaNJHknyqVb//STbkzzQpjOHtrk0ydYkjyc5fai+ttW2JrlkqH5Ckrtb/c+THDyu85GkURtnD/hV4NNVtRo4BdiQZHVb9idVdWKbbgFoy84F3gWsBb6QZEmSJcBG4AxgNXDe0H7+qO3rncALwAVjPB9JGqmxBXBVPVtV97X5l4HHgD09Nv8s4Pqq+klVfR/YCpzUpq1V9WRV/RS4HjgrSYAPAX/Ztr8WOHssJyNJYzAnY8BJjgfeA9zdShcleTDJpiRHttrRwDNDm21rtd3VfxH4UVW9+rr6TMdfn2RLki3PPffcKE5Jkvbb2AM4yaHAV4CLq+ol4Argl4ATgWeBPx53G6rqyqpaU1Vrli9fPu7DSdKsjPWlnEnewiB8v1RVNwJU1Y6h5V8Evta+bgeOHdr8mFZjN/UfAkckOaj1gofXl6R5b5xXQQS4Gnisqj4/VD9qaLXfAh5u8zcD5yZ5a5ITgFXAd4B7gFXtioeDGfxQd3NVFXAn8JG2/TrgpnGdjySN2jh7wKcCHwUeSvJAq/0eg6sYTgQKeAr4BEBVPZLkBuBRBldQbKiqKYAkFwG3A0uATVX1SNvf7wLXJ/kD4H4GgS9JC8LYAriqvgVkhkW37GGbzwGfm6F+y0zbVdWTDK6SkKQFxzvhJKkTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJamTsQVwkmOT3Jnk0SSPJPlUqy9LsjnJE+3zyFZPksuTbE3yYJL3Du1rXVv/iSTrhuq/muShts3lSTKu85GkURtnD/hV4NNVtRo4BdiQZDVwCXBHVa0C7mjfAc4AVrVpPXAFDAIbuAw4GTgJuGw6tNs6Hx/abu0Yz0eSRmpsAVxVz1bVfW3+ZeAx4GjgLODattq1wNlt/izguhq4CzgiyVHA6cDmqtpVVS8Am4G1bdnhVXVXVRVw3dC+pO6mpqZ48sknX5umpqZ6N0nzzEFzcZAkxwPvAe4GJqrq2bboB8BEmz8aeGZos22ttqf6thnqMx1/PYNeNccdd9x+nIk0e5OTk1y48VaWLpvglV07uGrDGaxcubJ3szSPjP1HuCSHAl8BLq6ql4aXtZ5rjbsNVXVlVa2pqjXLly8f9+Gk1yxdNsGhy49m6bKJva+sRWesAZzkLQzC90tVdWMr72jDB7TPna2+HTh2aPNjWm1P9WNmqEvSgjDOqyACXA08VlWfH1p0MzB9JcM64Kah+vntaohTgBfbUMXtwGlJjmw/vp0G3N6WvZTklHas84f2JUnz3jjHgE8FPgo8lOSBVvs94A+BG5JcAEwC57RltwBnAluBV4CPAVTVriSfBe5p632mqna1+U8C1wCHALe2SZIWhLEFcFV9C9jddbkfnmH9AjbsZl+bgE0z1LcA796PZkpSN94JJ0mdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1IkBLEmdGMCS1MnYAjjJpiQ7kzw8VPv9JNuTPNCmM4eWXZpka5LHk5w+VF/baluTXDJUPyHJ3a3+50kOHte5SNI4zCqAk5w6m9rrXAOsnaH+J1V1YptuaftaDZwLvKtt84UkS5IsATYCZwCrgfPaugB/1Pb1TuAF4ILZnIskzRez7QH/z1nWXlNV3wR2zXL/ZwHXV9VPqur7wFbgpDZtraonq+qnwPXAWUkCfAj4y7b9tcDZszyWJM0LB+1pYZJ/CvwasDzJbw8tOhxYso/HvCjJ+cAW4NNV9QJwNHDX0DrbWg3gmdfVTwZ+EfhRVb06w/ozncd6YD3Acccdt4/NlqTR2lsP+GDgUAZBfdjQ9BLwkX043hXALwEnAs8Cf7wP+3jTqurKqlpTVWuWL18+F4eUpL3aYw+4qr4BfCPJNVU1ub8Hq6od0/NJvgh8rX3dDhw7tOoxrcZu6j8EjkhyUOsFD68vSQvCbMeA35rkyiRfT/I309ObPViSo4a+/hYwfYXEzcC5Sd6a5ARgFfAd4B5gVbvi4WAGP9TdXFUF3MnPeuHrgJvebHskqac99oCH/AXwv4CrgKnZbJDky8AHgHck2QZcBnwgyYlAAU8BnwCoqkeS3AA8CrwKbKiqqbafi4DbGYw5b6qqR9ohfhe4PskfAPcDV8/yXCRpXphtAL9aVVe8mR1X1XkzlHcbklX1OeBzM9RvAW6Zof4kg6skJGlBmu0QxF8l+WSSo5Ism57G2jJJOsDNtge8rn3+zlCtgJWjbY4kLR6zCuCqOmHcDZGkxWZWAdxunHiDqrputM2RpMVjtkMQ7xuafxvwYeA+wACWpH002yGI/zj8PckRDJ7LIEnaR/v6OMq/AxwXlqT9MNsx4L9icNUDDG6I+EfADeNqlCQtBrMdA/4fQ/OvApNVtW0M7ZGkRWNWQxDtoTzfY/AktCOBn46zUZK0GMz2jRjnMHg4zr8BzgHuTrIvj6OUJDWzHYL4r8D7qmonQJLlwP/lZ2+kkCS9SbO9CuIXpsO3+eGb2FaSNIPZ9oBvS3I78OX2/d8ywxPKJPU3NTXF5OTg/QkrVqxgyZJ9fXuY4Of/njDav+ne3gn3TmCiqn4nyb8C3t8WfRv40khaIGmkJicnuXDjrQBcteEMVq70mVn7Y/rvuXTZBK/s2jHSv+neesB/ClwKUFU3AjcCJPnHbdm/HEkrJI3U0mUTvZtwQFm6bIJDl+/2vb/7bG/juBNV9dDri612/MhbI0mLyN4C+Ig9LDtkhO2QpEVnbwG8JcnHX19MciFw73iaJEmLw97GgC8Gvprk3/GzwF0DHMzgrcaSpH20xwCuqh3AryX5IPDuVv7rqnrTr6SXJP282T4P+E7gzjG3RZIWFe9mk6RODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqRODGBJ6sQAlqROxhbASTYl2Znk4aHasiSbkzzRPo9s9SS5PMnWJA8mee/QNuva+k8kWTdU/9UkD7VtLk+ScZ2LJI3DOHvA1wBrX1e7BLijqlYBd7TvAGcAq9q0HrgCBoENXAacDJwEXDYd2m2djw9t9/pjSdK8NrYArqpvArteVz4LuLbNXwucPVS/rgbuAo5IchRwOrC5qnZV1QvAZmBtW3Z4Vd1VVQVcN7QvSVoQ5noMeKKqnm3zPwAm2vzRwDND621rtT3Vt81Ql6QFo9uPcK3nWnNxrCTrk2xJsuW5556bi0NK0l7NdQDvaMMHtM+drb4dOHZovWNabU/1Y2aoz6iqrqyqNVW1Zvny5ft9EpI0CnMdwDcD01cyrANuGqqf366GOAV4sQ1V3A6cluTI9uPbacDtbdlLSU5pVz+cP7QvSVoQDhrXjpN8GfgA8I4k2xhczfCHwA1JLgAmgXPa6rcAZwJbgVeAjwFU1a4knwXuaet9pqqmf9j7JIMrLQ4Bbm2TJC0YYwvgqjpvN4s+PMO6BWzYzX42AZtmqG8B3r0/bZSknrwTTpI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6GdudcJI0LlNTU0xOTgKwYsUKlixZ0rlF+8YesKQFZ3Jykgs33sqFG299LYgXInvAkhakpcsm9r7SPGcPWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRNvxFAXw7eSwsK+nVTaVwawupi+lXTpsgle2bWDqzacwcqVK3s3S5pTBrC6WbpsgkOXH927GVI3jgFLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUicGsCR1YgBLUie+E06LwvBbmH0Ds+YLe8BaFKbfwnzhxltfC2KpN3vAWjSWLpvo3QTp59gDlqROugRwkqeSPJTkgSRbWm1Zks1JnmifR7Z6klyeZGuSB5O8d2g/69r6TyRZ1+NcJGlf9ewBf7CqTqyqNe37JcAdVbUKuKN9BzgDWNWm9cAVMAhs4DLgZOAk4LLp0JakhWA+DUGcBVzb5q8Fzh6qX1cDdwFHJDkKOB3YXFW7quoFYDOwdo7bLEn7rFcAF/D1JPcmWd9qE1X1bJv/ATD9i8nRwDND225rtd3V3yDJ+iRbkmx57rnnRnUOkrRfel0F8f6q2p7kHwCbk3xveGFVVZIa1cGq6krgSoA1a9aMbL+StD+69ICranv73Al8lcEY7o42tED73NlW3w4cO7T5Ma22u7okLQhzHsBJ3p7ksOl54DTgYeBmYPpKhnXATW3+ZuD8djXEKcCLbajiduC0JEe2H99OazVJWhB6DEFMAF9NMn38P6uq25LcA9yQ5AJgEjinrX8LcCawFXgF+BhAVe1K8lngnrbeZ6pq19ydhiTtnzkP4Kp6EvgnM9R/CHx4hnoBG3azr03AplG3UZLmwny6DE2SFhUDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqRMDWJI6MYAlqZNeb0XWDKamppicnARgxYoVLFmypHOLJI2TPeB5ZHJykgs33sqFG299LYglHbjsAc8zS5dN9G6CpDliD1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTA1iSOjGAJakTb8SQt0BLndgDlrdAS53YAxbgLdBSD/aAJakTA1iSOnEIYi/8gUrSuNgD3gt/oJI0LvaAZ8EfqCSNgz1gSerEAJakTgxgSerEAJakTgxgSerEAJakTgxgSerEAJakTgxgSerEAJakThZ8ACdZm+TxJFuTXNK7PZI0Wws6gJMsATYCZwCrgfOSrO7bKkmanYX+MJ6TgK1V9SRAkuuBs4BHR3mQV3btAODpp58e5W7f4Omnn56zY/U+7vAxX9m144D82871Oc503Ln8uy6WcxylVNVIdziXknwEWFtVF7bvHwVOrqqLXrfeemB9+/rLwONz2tB98w7g+d6NGLPFcI7geR5o9uU8n6+qta8vLvQe8KxU1ZXAlb3b8WYk2VJVa3q3Y5wWwzmC53mgGeV5LugxYGA7cOzQ92NaTZLmvYUewPcAq5KckORg4Fzg5s5tkqRZWdBDEFX1apKLgNuBJcCmqnqkc7NGZUENmeyjxXCO4HkeaEZ2ngv6RzhJWsgW+hCEJC1YBrAkdWIAzzNJNiXZmeTh3m0ZlyTHJrkzyaNJHknyqd5tGockb0vynSTfbef533q3aVySLElyf5Kv9W7LuCR5KslDSR5IsmUk+3QMeH5J8s+AHwPXVdW7e7dnHJIcBRxVVfclOQy4Fzi7qkZ6B2NvSQK8vap+nOQtwLeAT1XVXZ2bNnJJfhtYAxxeVb/Ruz3jkOQpYE1VjexmE3vA80xVfRPY1bsd41RVz1bVfW3+ZeAx4Oi+rRq9Gvhx+/qWNh1wPZ4kxwC/DlzVuy0LjQGsrpIcD7wHuLtzU8ai/df8AWAnsLmqDsTz/FPgvwB/37kd41bA15Pc2x5vsN8MYHWT5FDgK8DFVfVS7/aMQ1VNVdWJDO7SPCnJATWslOQ3gJ1VdW/vtsyB91fVexk8fXFDGy7cLwawumhjol8BvlRVN/Zuz7hV1Y+AO4E3PJBlgTsV+M02Pno98KEk/6dvk8ajqra3z53AVxk8jXG/GMCac+3HqauBx6rq873bMy5Jlic5os0fAvwL4HtdGzViVXVpVR1TVcczeBTA31TVv+/crJFL8vb2gzFJ3g6cBuz3lUoG8DyT5MvAt4FfTrItyQW92zQGpwIfZdBbeqBNZ/Zu1BgcBdyZ5EEGzy3ZXFUH7GVaB7gJ4FtJvgt8B/jrqrptf3fqZWiS1Ik9YEnqxACWpE4MYEnqxACWpE4MYEnqxACWdiPJxUmWDn2/Zfq6XmkUvAxNi1q7KSRV9YbnGIzj6VfSMHvAWnSSHJ/k8STXMbib6eokW4af2ZvkPwH/kMGNFHe22lNJ3tG2fyzJF9s2X293upHkfUkebDeX/PcD+bnO2n8GsBarVcAXqupdwKerag3wK8A/T/IrVXU58LfAB6vqg7vZfmPb/kfAv271/w18oj2AZ2rM56AFzgDWYjU59GD0c5LcB9wPvAtYPYvtv19VD7T5e4Hj2/jwYVX17Vb/sxG2VwegBf1aemk//B1AkhOA/wy8r6peSHIN8LZZbP+Tofkp4JCRt1AHPHvAWuwOZxDGLyaZYPCs12kvA4fNdkftkZMvJzm5lc4dVSN1YLIHrEWtqr6b5H4Gj4l8Bvh/Q4uvBG5L8re7GQeeyQXAF5P8PfAN4MWRNlgHFC9Dk0YoyaHT74FLcgmDl48ekG991v6zByyN1q8nuZTBv61J4D/0bY7mM3vAktSJP8JJUicGsCR1YgBLUicGsCR1YgBLUif/HxYBE75mQqpLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(x=ratings[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find/plot the user means rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1e71aa7f848>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(ratings.groupby([\"userId\"])[\"rating\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find/plot the item means rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1e71c825788>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(ratings.groupby([\"movieId\"])[\"rating\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Takeways:\n",
    "\n",
    "- as it's often the case on rating data, there is a high biais towards good ratings: people tend to rate things they like more than things they dislike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Explicit) Collaborative Filtering  by predicting ratings:\n",
    "\n",
    "The Netflix competition introduced the following predictive framework: the goal is to predict missing ratings using existing ones.\n",
    "\n",
    "In short, the goal is to define a model $f$ to predict how a user $u$ would rate an item $i$ : \n",
    "\n",
    "### $$ f(u,i) = r_{ui} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's build a train/test set\n",
    "\n",
    "Here, for simplicity, we take the 1 example out of 5 as a test example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes,test_indexes = [],[]\n",
    "\n",
    "for index in range(len(ratings)):\n",
    "    if index%5 == 0:\n",
    "        test_indexes.append(index)\n",
    "    else:\n",
    "        train_indexes.append(index)\n",
    "\n",
    "train_ratings = ratings.iloc[train_indexes].copy()\n",
    "test_ratings = ratings.iloc[test_indexes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In explicit collaborative filtering, the data are triplets of $(user,item,rating)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how one item is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2</td>\n",
       "      <td>131724</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating   timestamp\n",
       "260       2   131724     5.0  1445714851"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings[test_ratings[\"movieId\"] == 131724]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the triplet $(2,131724,5)$, the model goal will be to predict $f(2,131724) = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Recsys **mean** baselines implementations\n",
    "\n",
    "First, before digging into more complicated models, we'll implement three really simple baselines:\n",
    "\n",
    "- The global mean $\\mu$\n",
    "- The user mean $b_u$\n",
    "- The item mean $b_i$\n",
    "\n",
    "Indeed, the rating distribution is not uniform at all (it looks more normal). Therefore, the means are good baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: compute the global training mean, user means and item means\n",
    "\n",
    "- First, compute basic means to use them as baseline\n",
    "\n",
    "**NOTE**: User or items can be missing from train-set: be sure to return something in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = train_ratings[\"rating\"].mean()\n",
    "USER_MEANS = train_ratings.groupby(\"userId\")[\"rating\"].mean()\n",
    "ITEM_MEANS = train_ratings.groupby(\"movieId\")[\"rating\"].mean()\n",
    "\n",
    "\n",
    "def mean_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    return MEAN\n",
    "\n",
    "def user_mean_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    if user in USER_MEANS.index.values:\n",
    "        return USER_MEANS[user]\n",
    "    \n",
    "    return MEAN\n",
    "\n",
    "def item_mean_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    if item in ITEM_MEANS.index.values:\n",
    "        return ITEM_MEANS[item]\n",
    "    \n",
    "    return MEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should be able to run the following cell to get mean predictions (instead of None's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mean_prediction</th>\n",
       "      <th>muser_prediction</th>\n",
       "      <th>mitem_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.861446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983650</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.584906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981680</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>4.248691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980962</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>4.148374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating  timestamp  mean_prediction  muser_prediction  \\\n",
       "0        1        1     4.0  964982703         3.501915          4.345946   \n",
       "5        1       70     3.0  964982400         3.501915          4.345946   \n",
       "10       1      163     5.0  964983650         3.501915          4.345946   \n",
       "15       1      260     5.0  964981680         3.501915          4.345946   \n",
       "20       1      356     4.0  964980962         3.501915          4.345946   \n",
       "\n",
       "    mitem_prediction  \n",
       "0           3.861446  \n",
       "5           3.613636  \n",
       "10          3.584906  \n",
       "15          4.248691  \n",
       "20          4.148374  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create the rating prediction columns\n",
    "test_ratings[\"mean_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(mean_rating_pred,axis=1)\n",
    "test_ratings[\"muser_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(user_mean_rating_pred,axis=1) \n",
    "test_ratings[\"mitem_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(item_mean_rating_pred,axis=1) \n",
    "\n",
    "test_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, now that we've got some predictions, let's evaluate them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics:\n",
    "\n",
    "In explicit collaborative filtering there are three common metrics to compare a ground truth $x$ to a predicted $\\hat{x}$:\n",
    "\n",
    "- Mean Average Error (MAE) : $$\\frac{1}{n}\\sum^n|(x-\\hat{x})|$$\n",
    "- Mean Squared Error (MSE) : $$\\frac{1}{n}\\sum^n(x-\\hat{x})^2$$\n",
    "- Rooted Mean Squared Error (RMSE) : $$\\sqrt{\\frac{1}{n}\\sum^n(x-\\hat{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implement those metrics\n",
    "\n",
    "**Note:** The `predictions` and `truth` variables are arrays of predictions/ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def mae(predictions,truth):\n",
    "    return np.mean(np.abs(truth-predictions))\n",
    "\n",
    "def mse(predictions,truth):\n",
    "    return np.mean((truth-predictions)**2)\n",
    "\n",
    "def rmse(predictions,truth):\n",
    "    return np.sqrt(np.mean((truth-predictions)**2))\n",
    "\n",
    "\n",
    "def all_metrics(predictions,truth):\n",
    "    return [f(predictions,truth) for f in [mae,mse,rmse]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should be able to run the following cell to get the metrics results (Instead of None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mean_prediction  muser_prediction  mitem_prediction\n",
      "metrics                                                     \n",
      "mae             0.820963          0.729720          0.746088\n",
      "mse             1.076696          0.879324          0.937027\n",
      "rmse            1.037640          0.937723          0.968001\n",
      "\n",
      "---Best Models / Metrics: ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "metrics\n",
       "mae     muser_prediction\n",
       "mse     muser_prediction\n",
       "rmse    muser_prediction\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\"mae\",\"mse\",\"rmse\"]\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results[\"metrics\"] = metrics\n",
    "results[\"mean_prediction\"] = all_metrics(test_ratings[\"mean_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"muser_prediction\"] = all_metrics(test_ratings[\"muser_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"mitem_prediction\"] = all_metrics(test_ratings[\"mitem_prediction\"],test_ratings[\"rating\"])\n",
    "results = results.set_index(\"metrics\")\n",
    "\n",
    "print(results)\n",
    "print(\"\")\n",
    "print('---Best Models / Metrics: ---')\n",
    "results.idxmin(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic explicit collaborative filtering models - using surprise library\n",
    "\n",
    "> Surprise is an easy-to-use Python scikit for recommender systems.\n",
    "\n",
    "> Surprise has a set of built-in algorithms and datasets for you to play with. In its simplest form, it only takes a few lines of code to run a cross-validation procedure:\n",
    "\n",
    "[More details on the official documentation](https://surprise.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this to install required packages if needed (and restart kernel !)\n",
    "#! pip install --upgrade scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading custom data\n",
    "\n",
    "We want to be able to load our custom dataset in the framework data structures.  \n",
    "To do so, we could either load from a raw file or from a dataframe. We do the latter.\n",
    "\n",
    "(Here is the [Documentation reference](https://surprise.readthedocs.io/en/stable/getting_started.html#use-a-custom-dataset) for loading custom datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor, BaselineOnly, SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(train_ratings[['userId', 'movieId', 'rating']], Reader(rating_scale=(1, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do models work in Surprise ?\n",
    "\n",
    "It's fairly easy, Surprise follows the \"scikit\" way of doing things:\n",
    "```python\n",
    "model = GoodModel(params)\n",
    "model.fit(train_data)\n",
    "predictions = model.predict(test_data)\n",
    "```\n",
    "\n",
    "Ok, let's dig in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The baseline model:\n",
    "\n",
    ">Typical CF data exhibit large user and item effects—systematic tendencies for\n",
    "some users to give higher ratings than others—and for some items to receive\n",
    "higher ratings than others. It is customary to adjust the data by accounting for\n",
    "these effects, which we encapsulate within the baseline estimates. Denote by\n",
    "μ the overall average rating. A baseline estimate for an unknown rating r ui is\n",
    "denoted by b ui and accounts for the user and item effects:\n",
    "\n",
    "## $$ \\hat{r}_{ui} = b_{ui} = \\mu + b_u + b_i $$\n",
    "\n",
    "(If user u is unknown, then the bias bu is assumed to be zero. The same applies for item i with bi.)\n",
    "\n",
    "> The parameters b u and b i indicate the observed deviations of user u and item i,\n",
    "respectively, from the average. For example, suppose that we want a baseline\n",
    "estimate for the rating of the movie Titanic by user Joe. Now, say that the\n",
    "average rating over all movies, μ, is 3.7 stars. Furthermore, Titanic is better\n",
    "than an average movie, so it tends to be rated 0.5 stars above the average. On\n",
    "the other hand, Joe is a critical user, who tends to rate 0.3 stars lower than the\n",
    "average. Thus, the baseline estimate for Titanic’s rating by Joe would be 3.9\n",
    "stars by calculating 3.7 − 0.3 + 0.5.\n",
    "\n",
    "(see [Yehuda Koren. Factor in the neighbors: scalable and accurate collaborative filtering. 2010.](http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1e71d1fff08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaselineModel = BaselineOnly()\n",
    "BaselineModel.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Predict\n",
    "If you look at the [Prediction module](https://surprise.readthedocs.io/en/stable/predictions_module.html) documentation,\n",
    "you'll see that it has a little twist w/ respect to the traditional scikit \"predict\". It returns a Prediction \"[namedTuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)\" with the following fields:\n",
    "\n",
    "- uid – The (raw) user id. (raw means it's the one you supplied, not the one automatically computed by surprise)\n",
    "- iid – The (raw) item id.\n",
    "- r_ui (float) – The true rating rui\n",
    "- est (float) – The estimated rating $r_{ui}$\n",
    "- details (dict) – Stores additional details about the prediction that might be useful for later analysis.\n",
    "\n",
    "**=>** if you have a namedTuple `prediction`: `prediction.uid` will contain the user id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mean_prediction</th>\n",
       "      <th>muser_prediction</th>\n",
       "      <th>mitem_prediction</th>\n",
       "      <th>opt_bl_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.861446</td>\n",
       "      <td>4.531855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>4.325943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983650</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>3.584906</td>\n",
       "      <td>4.268825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981680</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>4.248691</td>\n",
       "      <td>4.890212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964980962</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>4.345946</td>\n",
       "      <td>4.148374</td>\n",
       "      <td>4.793284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100815</th>\n",
       "      <td>610</td>\n",
       "      <td>158721</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1479542491</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.700768</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.638797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100820</th>\n",
       "      <td>610</td>\n",
       "      <td>160341</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1479545749</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.700768</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.638797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100825</th>\n",
       "      <td>610</td>\n",
       "      <td>161634</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848362</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.700768</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.552825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100830</th>\n",
       "      <td>610</td>\n",
       "      <td>166528</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493879365</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.700768</td>\n",
       "      <td>3.931818</td>\n",
       "      <td>3.935317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "      <td>3.501915</td>\n",
       "      <td>3.700768</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.444219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20168 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp  mean_prediction  \\\n",
       "0            1        1     4.0   964982703         3.501915   \n",
       "5            1       70     3.0   964982400         3.501915   \n",
       "10           1      163     5.0   964983650         3.501915   \n",
       "15           1      260     5.0   964981680         3.501915   \n",
       "20           1      356     4.0   964980962         3.501915   \n",
       "...        ...      ...     ...         ...              ...   \n",
       "100815     610   158721     3.5  1479542491         3.501915   \n",
       "100820     610   160341     2.5  1479545749         3.501915   \n",
       "100825     610   161634     4.0  1493848362         3.501915   \n",
       "100830     610   166528     4.0  1493879365         3.501915   \n",
       "100835     610   170875     3.0  1493846415         3.501915   \n",
       "\n",
       "        muser_prediction  mitem_prediction  opt_bl_prediction  \n",
       "0               4.345946          3.861446           4.531855  \n",
       "5               4.345946          3.613636           4.325943  \n",
       "10              4.345946          3.584906           4.268825  \n",
       "15              4.345946          4.248691           4.890212  \n",
       "20              4.345946          4.148374           4.793284  \n",
       "...                  ...               ...                ...  \n",
       "100815          3.700768          3.501915           3.638797  \n",
       "100820          3.700768          3.501915           3.638797  \n",
       "100825          3.700768          3.166667           3.552825  \n",
       "100830          3.700768          3.931818           3.935317  \n",
       "100835          3.700768          2.000000           3.444219  \n",
       "\n",
       "[20168 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def opt_bl_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    prediction = BaselineModel.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "test_ratings[\"opt_bl_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(opt_bl_rating_pred,axis=1) \n",
    "\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn !\n",
    "\n",
    "### __A QUICK NOTE:__ The baseline algorithm is really strong on this dataset, don't worry if the following models performance is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Algorithm\n",
    "\n",
    "First, let's try the famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize. \n",
    "\n",
    "> Matrix factorization models map both users and items ratings. to a joint latent factor space of dimensionality f, such that user-item interactions are modeled as inner products in that space.\n",
    "\n",
    "A prediction is made in the following way:\n",
    "\n",
    "## $$\\hat{r}_{ui} = \\mu + b_u + b_i + q_i^Tp_u$$\n",
    "\n",
    " When baselines are not used, this is equivalent to Probabilistic Matrix Factorization. If user u is unknown, then the bias bu and the factors pu are assumed to be zero. The same applies for item i with bi and qi.\n",
    "\n",
    "[This is the seminal paper associated to this model](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : Try and use the `SVD` surprise model ([related documentation page](https://surprise.readthedocs.io/en/stable/matrix_factorization.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1e71bb0a2c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDmodel = SVD()\n",
    "SVDmodel.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07767469045846667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pu = SVDmodel.pu\n",
    "qi = SVDmodel.qi\n",
    "qi[0].T @ pu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Use the surprise SVD Implementation to predict missing ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    prediction = SVDmodel.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "test_ratings[\"svd_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(svd_rating_pred,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare every algorithm: the following cell should run and give you the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mean_prediction  muser_prediction  mitem_prediction  \\\n",
      "metrics                                                        \n",
      "mae             0.820963          0.729720          0.746088   \n",
      "mse             1.076696          0.879324          0.937027   \n",
      "rmse            1.037640          0.937723          0.968001   \n",
      "\n",
      "         opt_bl_prediction  svd_prediction  \n",
      "metrics                                     \n",
      "mae               0.664942        0.667016  \n",
      "mse               0.748537        0.758788  \n",
      "rmse              0.865180        0.871084  \n",
      "\n",
      "---Best Models / Metrics: ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "metrics\n",
       "mae     opt_bl_prediction\n",
       "mse     opt_bl_prediction\n",
       "rmse    opt_bl_prediction\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\"mae\",\"mse\",\"rmse\"]\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results[\"metrics\"] = metrics\n",
    "results[\"mean_prediction\"] = all_metrics(test_ratings[\"mean_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"muser_prediction\"] = all_metrics(test_ratings[\"muser_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"mitem_prediction\"] = all_metrics(test_ratings[\"mitem_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"opt_bl_prediction\"] = all_metrics(test_ratings[\"opt_bl_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"svd_prediction\"] = all_metrics(test_ratings[\"svd_prediction\"],test_ratings[\"rating\"])\n",
    "\n",
    "results = results.set_index(\"metrics\")\n",
    "\n",
    "print(results)\n",
    "print(\"\")\n",
    "print('---Best Models / Metrics: ---')\n",
    "results.idxmin(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing learnt embeddings\n",
    "\n",
    "> Factorizing the user-movie matrix allows us to discover the most descriptive dimensions for predicting movie preferences. We can identify the first few most important dimensions from a matrix decomposition and explore the movies’ location in this new space.\n",
    "\n",
    "To do so, we propose to use the [Tensorflow projector](https://projector.tensorflow.org/), an accessible easy to use tool online. The following functions/cells walks you through saving both the learnt movie embeddings and labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The saving function:\n",
    "\n",
    "This function saves embeddings (a numpy array) and associated labels into tsv files which can be used by the [Tensorflow projector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embs,dict_label,path=\"saved_word_vectors\"):\n",
    "    \"\"\"\n",
    "    embs is Numpy.array(N,size)\n",
    "    dict_label is {str(word)->int(idx)} or {int(idx)->str(word)}\n",
    "    \"\"\"\n",
    "    def int_first(k,v):\n",
    "        if type(k) == int:\n",
    "            return (k,v)\n",
    "        else:\n",
    "            return (v,k)\n",
    "\n",
    "    np.savetxt(f\"{path}_vectors.tsv\", embs, delimiter=\"\\t\")\n",
    "\n",
    "    #labels \n",
    "    if dict_label:\n",
    "        sorted_labs = np.array([lab for idx,lab in sorted([int_first(k,v) for k,v in dict_label.items()])])\n",
    "        print(sorted_labs)\n",
    "        with open(f\"{path}_metadata.tsv\",\"w\") as metadata_file:\n",
    "            for x in sorted_labs: #hack for space\n",
    "                if len(x.strip()) == 0:\n",
    "                    x = f\"space-{len(x)}\"\n",
    "                    \n",
    "                metadata_file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading the movie titles.\n",
    "\n",
    "We want to label our movie with their titles (indeed, the movieId is not really informative about content)\n",
    "=> We just read the .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleCSV = pd.read_csv(\"dataset/movies.csv\")\n",
    "titleCSV.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) We extract a mapping id => title  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Toy Story (1995)'),\n",
       " (2, 'Jumanji (1995)'),\n",
       " (3, 'Grumpier Old Men (1995)'),\n",
       " (4, 'Waiting to Exhale (1995)'),\n",
       " (5, 'Father of the Bride Part II (1995)'),\n",
       " (6, 'Heat (1995)'),\n",
       " (7, 'Sabrina (1995)'),\n",
       " (8, 'Tom and Huck (1995)'),\n",
       " (9, 'Sudden Death (1995)'),\n",
       " (10, 'GoldenEye (1995)')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2title = titleCSV[[\"movieId\",\"title\"]].set_index(\"movieId\").to_dict()[\"title\"]\n",
    "list(id2title.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) We map the inner surprise id's to the raw id's to the movie title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89758190e-01,  1.13073715e-01,  9.25107541e-03, ...,\n",
       "         2.19387331e-01, -4.93106463e-03,  2.16064606e-01],\n",
       "       [-7.27921027e-02,  8.49059093e-02, -1.39084311e-01, ...,\n",
       "         6.25407575e-02, -2.85090609e-01,  8.74559618e-02],\n",
       "       [-1.68228970e-02, -2.87131863e-01, -9.57915572e-02, ...,\n",
       "        -3.18242504e-01, -3.36118629e-02,  6.78952939e-02],\n",
       "       ...,\n",
       "       [-1.08014235e-01, -5.47923187e-01, -4.61493458e-02, ...,\n",
       "         2.35554459e-01, -1.15163301e-01,  1.98046927e-01],\n",
       "       [-2.33471066e-01, -1.08324233e-01,  3.09005020e-02, ...,\n",
       "        -5.29275578e-02,  6.15905215e-03, -2.55701366e-02],\n",
       "       [-1.45026013e-04,  1.40321293e-01,  1.29048138e-03, ...,\n",
       "         2.18544534e-03, -1.08945694e-01,  7.04602658e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = data.build_full_trainset()\n",
    "index2movie = {x:id2title[full_data.to_raw_iid(x)] for x in full_data.all_items()}\n",
    "SVDmodel.qi # Holds product vectors\n",
    "SVDmodel.pu # Holds user vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Finally, we save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grumpier Old Men (1995)' 'Heat (1995)' 'Seven (a.k.a. Se7en) (1995)' ...\n",
      " 'Hazard (2005)' 'Blair Witch (2016)' '31 (2016)']\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(SVDmodel.qi,index2movie,path=\"svd_items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improving your results with GridSearch :\n",
    "\n",
    "Every machine learning model is sensible to hyperparameters: Hopefully, surprise provides a way to do parameter search [(related docs)](https://surprise.readthedocs.io/en/stable/model_selection.html#parameter-search). Here's how it work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9634341f2619>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rmse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mae'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# you choose the algorithm and the measures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# You look at best combinations (automatically deals with train/validation splits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\model_selection\\search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     88\u001b[0m         out = Parallel(n_jobs=self.n_jobs,\n\u001b[0;32m     89\u001b[0m                        \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                        verbose=self.joblib_verbose)(delayed_list)\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         (test_measures_dicts,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\model_selection\\validation.py\u001b[0m in \u001b[0;36mfit_and_score\u001b[1;34m(algo, trainset, testset, measures, return_train_measures)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mstart_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mstart_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\surprise\\trainset.py\u001b[0m in \u001b[0;36mall_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {'n_epochs': list(range(2,8)),'lr_all': [0.002, 0.005],'reg_all': [0.2,0.4, 0.6]} #you can add parameters\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3) # you choose the algorithm and the measures\n",
    " \n",
    "gs.fit(data) # You look at best combinations (automatically deals with train/validation splits)\n",
    "\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best validation RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo = gs.best_estimator['rmse']\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    prediction = algo.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "test_ratings[\"algo_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(algo_rating_pred,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Finally, try improving your score by testing out all of surprise models and possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO)  Use, for example, the KNNs algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic, KNNWithMeans\n",
    "\n",
    "KNNmodel = KNNBasic()\n",
    "KNNmodel.fit(data.build_full_trainset())\n",
    "\n",
    "def knn_rating_pred(user_item):\n",
    "    user = user_item[\"userId\"]\n",
    "    item = user_item[\"movieId\"]\n",
    "    \n",
    "    prediction = KNNmodel.predict(user,item)\n",
    "    \n",
    "    return prediction.est\n",
    "\n",
    "test_ratings[\"knn_prediction\"] = test_ratings[[\"userId\",\"movieId\"]].apply(knn_rating_pred,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"mae\",\"mse\",\"rmse\"]\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results[\"metrics\"] = metrics\n",
    "results[\"mean_prediction\"] = all_metrics(test_ratings[\"mean_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"muser_prediction\"] = all_metrics(test_ratings[\"muser_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"mitem_prediction\"] = all_metrics(test_ratings[\"mitem_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"opt_bl_prediction\"] = all_metrics(test_ratings[\"opt_bl_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"svd_prediction\"] = all_metrics(test_ratings[\"svd_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"knn_prediction\"] = all_metrics(test_ratings[\"knn_prediction\"],test_ratings[\"rating\"])\n",
    "results[\"algo_prediction\"] = all_metrics(test_ratings[\"algo_prediction\"],test_ratings[\"rating\"])\n",
    "\n",
    "results = results.set_index(\"metrics\")\n",
    "\n",
    "print(results)\n",
    "print(\"\")\n",
    "print('---Best Models / Metrics: ---')\n",
    "results.idxmin(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still some time left: [have you tried them all ?](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
